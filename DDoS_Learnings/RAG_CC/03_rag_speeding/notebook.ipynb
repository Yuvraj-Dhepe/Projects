{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "feeb1434",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload \n",
    "%autoreload 2\n",
    "import os\n",
    "import nest_asyncio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, Markdown, clear_output\n",
    "from raggie import embedder, vecdb, retriever, raggy, utils\n",
    "\n",
    "nest_asyncio.apply()\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8769bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "QDRANT_HOST = os.getenv(\"QDRANT_HOST\", \"localhost\")\n",
    "QDRANT_PORT = int(os.getenv(\"QDRANT_PORT\", 6333))\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_HOST\", \"http://localhost:11434\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d35c3b",
   "metadata": {},
   "source": [
    "## Traditional RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ccd5b",
   "metadata": {},
   "source": [
    "- In the previous code, the heavy lifting was happening behind the scenes:\n",
    "    - llama-index taking care of the chunking and embedding part \n",
    "    - qdrant taking care of the indexing the embeddings and storing them \n",
    "    - llama-index taking care of retrieving the embeddings from the vector db \n",
    "    - llama-index also faciliated the reranking step for us \n",
    "    \n",
    "- However, in this nb session, we would like to handle some bits ourselves:\n",
    "    - Creation of embeddings \n",
    "    - Indexing is still taken care by Qdrant, we just tune it \n",
    "    - Retrieval of context from vectorDB \n",
    "    - Combining the above 3 steps, to create a simple end to end RAG pipeline\n",
    "\n",
    "- As we are building the components ourselves step by step, we will see, where can we do the optimizations to improve the speed of the RAG system "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98bfdbfe",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b248cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "## Step 1: Load the SQuAD dataset\n",
    "dataset = load_dataset(\"squad\")\n",
    "\n",
    "## Step 2 : Extract unique contexts from the dataset\n",
    "data = [item[\"context\"] for item in dataset[\"train\"]]\n",
    "texts = list(set(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0953ec00",
   "metadata": {},
   "source": [
    "### Embed Dataset\n",
    "- EmbedData does the job of loading the embedding model & embedding the dataset & storing them \n",
    "- With the class instance, we will embed the dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1ffc7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "embeddata = embedder.EmbedData(batch_size=batch_size)\n",
    "embeddata.embed(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e50b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddata.embeddings[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5e6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    utils.pretty_print(embeddata.contexts[0]),\n",
    "    utils.pretty_print(embeddata.embeddings[0]),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fa25e11",
   "metadata": {},
   "source": [
    "### Vector DB\n",
    "- QdrantVDB will help us interact with the vector DB. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84d3346",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = vecdb.QdrantVDB(\n",
    "    collection_name=\"dummy\", vector_dim=1024, batch_size=512\n",
    ")\n",
    "database.define_client()\n",
    "database.create_collection()\n",
    "database.ingest_data(embeddata)\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fd9e1e",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a7466a",
   "metadata": {},
   "source": [
    "- Encapsulate the logic for searching the vector db using a query (of string type)\n",
    "- Using the embedding model and vector db, we can retrieve the most relevant contexts based on the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd4bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(database.client.count(collection_name=\"dummy\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11058b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = retriever.Retriever(database, embeddata).search(\"Sample Query\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56671a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "for data in result.points:\n",
    "    utils.pretty_print(dict(data)[\"payload\"][\"context\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df90e56",
   "metadata": {},
   "source": [
    "\n",
    "### RAG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d408de63",
   "metadata": {},
   "source": [
    "- Essentially we will club the retriever with the LLM to wrap up the pipeline \n",
    "- The retriever in itself wraps up the embedder and the vector DB functionalities \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c84b69c0",
   "metadata": {},
   "source": [
    "### Using RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667eece2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rv = retriever.Retriever(database, embeddata)\n",
    "rag = raggy.RAG(rv)\n",
    "\n",
    "\n",
    "# Taking a look at dummy data, and forming a query based on it\n",
    "utils.pretty_print(embeddata.contexts[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a7cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some of the techniques used to study bird migration routes?\"\n",
    "context, response = rag.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da0f073",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.pretty_print(context)\n",
    "utils.pretty_print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d3dd72",
   "metadata": {},
   "source": [
    "### Binary Quantization Optimizations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9612376b",
   "metadata": {},
   "source": [
    "- In binary quantization, we convert positive and negative values to 1s and 0s\n",
    "- Because of this 2 things happen:\n",
    "    - We reduce the size of the vector embeddings by 4x (float32 to binary)\n",
    "    - We can use bitwise operations to calculate similarity which are much faster \n",
    "    than floating point operations\n",
    "- Below are few visualizations showcasing the quantizations, showing how still \n",
    "there is presence of data to be interpretted after quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e1ea1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# 1. Create a float32 \"image\"\n",
    "# -----------------------------\n",
    "img_f32 = np.random.rand(1, 256)  # values in [0, 1]\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 3, 1)\n",
    "plt.plot(img_f32[0])\n",
    "plt.title(\"Original float32\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Convert to float16\n",
    "# -----------------------------\n",
    "img_f16 = img_f32.astype(np.float16)\n",
    "plt.subplot(2, 3, 2)\n",
    "plt.plot(img_f16[0])\n",
    "plt.title(\"float16\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Quantize to \"float8\" (256 levels)\n",
    "# -----------------------------\n",
    "levels8 = 256\n",
    "img_f8 = np.round(img_f32 * (levels8 - 1)) / (levels8 - 1)\n",
    "plt.subplot(2, 3, 3)\n",
    "plt.plot(img_f8[0])\n",
    "plt.title(\"float8 (256 levels)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Quantize to \"float4\" (16 levels)\n",
    "# -----------------------------\n",
    "levels4 = 16\n",
    "img_f4 = np.round(img_f32 * (levels4 - 1)) / (levels4 - 1)\n",
    "plt.subplot(2, 3, 4)\n",
    "plt.plot(img_f4[0])\n",
    "plt.title(\"float4 (16 levels)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Quantize to \"float2\" (4 levels)\n",
    "# -----------------------------\n",
    "levels2 = 4\n",
    "img_f2 = np.round(img_f32 * (levels2 - 1)) / (levels2 - 1)\n",
    "plt.subplot(2, 3, 5)\n",
    "plt.plot(img_f2[0])\n",
    "plt.title(\"float2 (4 levels)\")\n",
    "\n",
    "# -----------------------------\n",
    "# 6. Quantize to binary (1-bit)\n",
    "# -----------------------------\n",
    "img_bin = (img_f32 >= 0.5).astype(np.float32)\n",
    "plt.subplot(2, 3, 6)\n",
    "plt.plot(img_bin[0])\n",
    "plt.title(\"Binary (1-bit)\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bad9f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: Black means 0, White means 1, white represents\n",
    "# higher values/ essential information.\n",
    "# -----------------------------\n",
    "# 1. Create a random vector (float32)\n",
    "# -----------------------------\n",
    "vector = np.random.rand(1, 512).astype(np.float32)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Define quantization function\n",
    "# -----------------------------\n",
    "def quantize_vector(vec, levels):\n",
    "    return np.round(vec * (levels - 1)) / (levels - 1)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Create all quantized versions\n",
    "# -----------------------------\n",
    "vector_f32 = vector.copy()\n",
    "vector_f16 = vector.astype(np.float16)\n",
    "vector_f8 = quantize_vector(vector, 256)\n",
    "vector_f4 = quantize_vector(vector, 16)\n",
    "vector_f2 = quantize_vector(vector, 4)\n",
    "vector_bin = (vector >= 0.5).astype(np.float32)\n",
    "\n",
    "vectors = [\n",
    "    vector_f32,\n",
    "    vector_f16,\n",
    "    vector_f8,\n",
    "    vector_f4,\n",
    "    vector_f2,\n",
    "    vector_bin,\n",
    "]\n",
    "titles = [\"float32\", \"float16\", \"float8\", \"float4\", \"float2\", \"binary\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Plot heatmaps in a single column (6 rows × 1 col)\n",
    "# -----------------------------\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "for i, (v, t) in enumerate(zip(vectors, titles)):\n",
    "    plt.subplot(6, 1, i + 1)  # <-- 6 rows, 1 column\n",
    "    plt.imshow(v, aspect=\"auto\", cmap=\"grey\")\n",
    "    plt.title(t, fontsize=12)\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6a08b9",
   "metadata": {},
   "source": [
    "- To perform the binary quantization, we have to modify bits at 2 places: \n",
    "    - In the vector DB, we add a quantization config, to quantize the data during storage\n",
    "    - In retriever code, when we are searching the params for quantization, we change ignore from True to False\n",
    "\n",
    "- After these changes, we will now be quantizing the vectors during storing and retrieval \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea2f86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the new vector DB with binary quantization\n",
    "bq_database = vecdb.QdrantVDB(\n",
    "    collection_name=\"bq_dummy\", vector_dim=1024, batch_size=512, bq=True\n",
    ")\n",
    "bq_database.define_client()\n",
    "bq_database.create_collection()\n",
    "bq_database.ingest_data(embeddata)\n",
    "\n",
    "\n",
    "# Retriever with binary quantization\n",
    "retriever_bq = retriever.Retriever(bq_database, embeddata, bq=True)\n",
    "\n",
    "# RAG with binary quantization\n",
    "rag = raggy.RAG(retriever_bq)\n",
    "\n",
    "clear_output()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf93a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are some of the techniques used to study bird migration routes?\"\n",
    "context, response = rag.query(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354d9138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utils.pretty_print(context)\n",
    "utils.pretty_print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e57e834",
   "metadata": {},
   "source": [
    "### Limitations of Binary Quantization:\n",
    "- Loss of Precision: Binary quantization reduces the precision of the original data, \n",
    "which can lead to a loss of important information, especially in complex datasets.     \n",
    "- Reduced Model Performance: Models that rely on high-precision data may experience\n",
    "a drop in performance when using binary quantized inputs, as they may not capture \n",
    "the nuances present in the original data.\n",
    "- The performance of binary quantization highly depends on the inital embeddings produced by the embedding model, if the embeddings are not well-optimized, quantization, may exacerbate inaccuracies.  \n",
    "\n",
    "### Minimizing the limitations \n",
    "- To minimize the limitations, we can oversample the vectors during the retrieval process, to gather more context for answering the QnA\n",
    "- Use the embedding models which produce high quality embeddings as well as long embeddings, as high quality embeddings ensure less loss in information after quantization. Also long embeddings account, that each dimension carries less information, so quantization wont' hurt that much loss of information. But yup it's always a trade-off between the vector length occupying more space too. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc621c3",
   "metadata": {},
   "source": [
    "### Summary \n",
    "- In general we saw the traditional rag setting in this nb, what is happening behind the scenes in a traditional RAG pipeline such as: \n",
    "    - An embedding part, necessary for generating text embeddings from the context. \n",
    "    - A vector db, handling efficient storage of the embeddings \n",
    "    - A retriever to retrieve contexts by making use of the query embedding and the vector db \n",
    "    - Lastly the use of LLM with the above bits, to return to user an answer based on the retrieved context "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG_CC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
