{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Asyncio \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Qdrant vector DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import qdrant_client\n",
    "\n",
    "collection_name=\"chat_with_docs\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "input_dir_path = './docs'\n",
    "loader = SimpleDirectoryReader(input_dir=input_dir_path, required_exts=['.pdf'], recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(docs), len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexing Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex, ServiceContext, StorageContext\n",
    "\n",
    "def create_index(documents):\n",
    "    vector_store = QdrantVectorStore(client=client, collection_name=collection_name)\n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    index = VectorStoreIndex.from_documents(documents, storage_context=storage_context)\n",
    "    return index\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Embedding Model & Indexing the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.core import Settings\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "                                   trust_remote_code=True)\n",
    "\n",
    "# Ensuring same model is used throughout the rag pipeline\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "# Convert each document into an embedding using the embed model\n",
    "index = create_index(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "llm = Ollama(model = 'llama3.2:1b', request_timeout=120.0, base_url=\"http://172.18.176.1:11434\")\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the Prompt Template "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = \"\"\"Context information is below:\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Given the context information above I want you to think\n",
    "              step by step to answer the query in a crisp manner,\n",
    "              incase you don't know the answer say 'I don't know!'\n",
    "\n",
    "              Query: {query_str}\n",
    "\n",
    "              Answer:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\",\n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=10,\n",
    "                                     node_postprocessors=[rerank])\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")\n",
    "\n",
    "response = query_engine.query(\"What exactly is DSPy?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Markdown, display\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ollama Ocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "a = cv2.imread(r\"../rewe_2025/01.jpg\")\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama_ocr import OCRProcessor\n",
    "\n",
    "# Initialize OCR processor\n",
    "ocr = OCRProcessor(model_name='llama3.2-vision:latest')  # You can use any vision model available on Ollama\n",
    "\n",
    "# Process an image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the structured data extracted from the German supermarket receipt in a JSON format:\n",
      "\n",
      "```\n",
      "{\n",
      "    \"receipt\": {\n",
      "        \"items\": [\n",
      "            {\n",
      "                \"name\": \"Kart. SP.\",\n",
      "                \"quantity\": 1,\n",
      "                \"total\": \"0,842\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": \"APFEL SALA\",\n",
      "                \"quantity\": 4.94,\n",
      "                \"total\": \"2,99\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": LIMETTE\",\n",
      "                \"quantity\": 4.49,\n",
      "                \"total\": \"3,66\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": RISPENTONATE BIO\",\n",
      "                \"quantity\": 2.26,\n",
      "                \"total\": \"2,39\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": ESL MILCH 3,5% GEMÜSESMISCHUNG\",\n",
      "                \"quantity\": 2.19,\n",
      "                \"total\": \"1,99\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": RÖHRZUCKER\",\n",
      "                \"quantity\": 2.85,\n",
      "                \"total\": \"2,09\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": PENE VOLKORN-MALDHOHENIG\",\n",
      "                \"quantity\": 0.95,\n",
      "                \"total\": \"1,99\"\n",
      "            },\n",
      "            {\n",
      "                \"name\": SPUELM SWEET DR.\",\n",
      "                \"quantity\": 0,\n",
      "                \"total\": \"2,39\"\n",
      "            }\n",
      "        ],\n",
      "        \"sum\": \"19,84\"\n",
      "    }\n",
      "}\n",
      "```\n",
      "\n",
      "This JSON structure accurately represents the details extracted from the receipt image, including item names, quantities (where applicable), total amounts for each item, and a summary of the total sum at the end.\n"
     ]
    }
   ],
   "source": [
    "result = ocr.process_image(\n",
    "    image_path=\"../rewe_2025/04.png\",\n",
    "    format_type=\"json\"  # Options: markdown, text, json, structured, key_value\n",
    ")\n",
    "print(result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
